Clus run df
***********

Date: 1/22/20 2:17 PM
File: Chainlink_depth3.out
Attributes: 3 (input: 3, output: 3)
Missing values: No

[General]
Verbose = 1
Compatibility = Latest
RandomSeed = 1
ResourceInfoLoaded = No

[Data]
File = Chainlink_depth3.arff
TestSet = None
PruneSet = 0.25
PruneSetMax = Infinity
XVal = 10
RemoveMissingTarget = No
NormalizeData = None

[Attributes]
Target = 1-3
Clustering = 1-3
Descriptive = 1-3
Key = None
Disable = None
Weights = Normalize
ClusteringWeights = 1.0
ReduceMemoryNominalAttrs = No

[Constraints]
Syntactic = None
MaxSize = Infinity
MaxError = 0.0
MaxDepth = 3

[Output]
ShowModels = {Default, Pruned, Others}
TrainErrors = Yes
ValidErrors = Yes
TestErrors = Yes
AllFoldModels = Yes
AllFoldErrors = No
AllFoldDatasets = No
UnknownFrequency = No
BranchFrequency = No
ShowInfo = {Count}
PrintModelAndExamples = No
WriteErrorFile = No
WritePredictions = {Train}
ModelIDFiles = No
WriteCurves = No
OutputPythonModel = No
OutputDatabaseQueries = No

[Nominal]
MEstimate = 1.0

[Model]
MinimalWeight = 5.0
MinimalNumberExamples = 0
MinimalKnownWeight = 0.0
ParamTuneNumberFolds = 10
ClassWeights = 0.0
NominalSubsetTests = Yes

[Tree]
Heuristic = VarianceReduction
PruningMethod = ReducedErrorVSB
FTest = 1.0
BinarySplit = Yes
ConvertToRules = No
AlternativeSplits = No
Optimize = {}
MSENominal = No
SplitSampling = None
InductionOrder = DepthFirst

Run: 01
*******

Statistics
----------

FTValue (FTest): 1.0
Induction Time: 0.019 sec
Pruning Time: 0.006 sec
Model information
     Default: Nodes = 1 (Leaves: 1)
     Original: Nodes = 15 (Leaves: 8)
     Pruned: Nodes = 15 (Leaves: 8)

Training error
--------------

Number of examples: 750
Mean absolute error (MAE)
   Default        : [0.3201,0.7288,0.3354]: 0.4615
   Original       : [0.1245,0.4555,0.1403]: 0.2401
   Pruned         : [0.1245,0.4555,0.1403]: 0.2401
Mean squared error (MSE)
   Default        : [0.2333,0.7722,0.2453]: 0.417
   Original       : [0.0347,0.3573,0.048]: 0.1467
   Pruned         : [0.0347,0.3573,0.048]: 0.1467
Root mean squared error (RMSE)
   Default        : [0.4831,0.8787,0.4953]: 0.6457
   Original       : [0.1863,0.5978,0.219]: 0.383
   Pruned         : [0.1863,0.5978,0.219]: 0.383
Weighted root mean squared error (RMSE) (Weights [4.163,1.306,4.163])
   Default        : [0.9856,1.0043,1.0107]: 1.0003
   Original       : [0.38,0.6832,0.4468]: 0.5199
   Pruned         : [0.38,0.6832,0.4468]: 0.5199
Pearson correlation coefficient
   Default        : [�,�,0], Avg r^2: �
   Original       : [0.9227,0.733,0.8969], Avg r^2: 0.731
   Pruned         : [0.9227,0.733,0.8969], Avg r^2: 0.731

Validation error
----------------

Number of examples: 250
Mean absolute error (MAE)
   Default        : [0.3573,0.7154,0.3176]: 0.4635
   Original       : [0.1234,0.4709,0.1351]: 0.2431
   Pruned         : [0.1234,0.4709,0.1351]: 0.2431
Mean squared error (MSE)
   Default        : [0.2608,0.7455,0.2251]: 0.4105
   Original       : [0.0313,0.3451,0.0451]: 0.1405
   Pruned         : [0.0313,0.3451,0.0451]: 0.1405
Root mean squared error (RMSE)
   Default        : [0.5106,0.8635,0.4744]: 0.6407
   Original       : [0.1768,0.5874,0.2124]: 0.3748
   Pruned         : [0.1768,0.5874,0.2124]: 0.3748
Weighted root mean squared error (RMSE) (Weights [4.163,1.306,4.163])
   Default        : [1.0419,0.9869,0.968]: 0.9994
   Original       : [0.3608,0.6714,0.4333]: 0.5062
   Pruned         : [0.3608,0.6714,0.4333]: 0.5062
Pearson correlation coefficient
   Default        : [0,�,-0], Avg r^2: �
   Original       : [0.9384,0.7368,0.8943], Avg r^2: 0.7411
   Pruned         : [0.9384,0.7368,0.8943], Avg r^2: 0.7411

Default Model
*************

[-0.006855,0.430912,-0.016542]: 750

Original Model
**************

V4 > -0.1831917
+--yes: V2 > -0.1195819
|       +--yes: V2 > 0.08377616
|       |       +--yes: [0.632672,-0.092531,0.005918]: 174
|       |       +--no:  [-0.00001,0.81406,0.476544]: 232
|       +--no:  V3 > 0.02438884
|               +--yes: [-0.659009,0.66783,-0.003655]: 66
|               +--no:  [-0.701687,-0.582563,0.003287]: 103
+--no:  V3 > 1.140747
        +--yes: V4 > -0.6260111
        |       +--yes: [0.002007,1.895928,-0.405967]: 24
        |       +--no:  [0.00313,1.624878,-0.761985]: 42
        +--no:  V4 > -0.7304934
                +--yes: [0.003415,0.135533,-0.485049]: 42
                +--no:  [0.003303,0.700152,-0.924976]: 67

Pruned Model
************

V4 > -0.1831917
+--yes: V2 > -0.1195819
|       +--yes: V2 > 0.08377616
|       |       +--yes: [0.632672,-0.092531,0.005918]: 174
|       |       +--no:  [-0.00001,0.81406,0.476544]: 232
|       +--no:  V3 > 0.02438884
|               +--yes: [-0.659009,0.66783,-0.003655]: 66
|               +--no:  [-0.701687,-0.582563,0.003287]: 103
+--no:  V3 > 1.140747
        +--yes: V4 > -0.6260111
        |       +--yes: [0.002007,1.895928,-0.405967]: 24
        |       +--no:  [0.00313,1.624878,-0.761985]: 42
        +--no:  V4 > -0.7304934
                +--yes: [0.003415,0.135533,-0.485049]: 42
                +--no:  [0.003303,0.700152,-0.924976]: 67

