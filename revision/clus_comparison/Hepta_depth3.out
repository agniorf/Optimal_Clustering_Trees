Clus run df
***********

Date: 1/22/20 2:17 PM
File: Hepta_depth3.out
Attributes: 3 (input: 3, output: 3)
Missing values: No

[General]
Verbose = 1
Compatibility = Latest
RandomSeed = 1
ResourceInfoLoaded = No

[Data]
File = Hepta_depth3.arff
TestSet = None
PruneSet = 0.25
PruneSetMax = Infinity
XVal = 10
RemoveMissingTarget = No
NormalizeData = None

[Attributes]
Target = 1-3
Clustering = 1-3
Descriptive = 1-3
Key = None
Disable = None
Weights = Normalize
ClusteringWeights = 1.0
ReduceMemoryNominalAttrs = No

[Constraints]
Syntactic = None
MaxSize = Infinity
MaxError = 0.0
MaxDepth = 3

[Output]
ShowModels = {Default, Pruned, Others}
TrainErrors = Yes
ValidErrors = Yes
TestErrors = Yes
AllFoldModels = Yes
AllFoldErrors = No
AllFoldDatasets = No
UnknownFrequency = No
BranchFrequency = No
ShowInfo = {Count}
PrintModelAndExamples = No
WriteErrorFile = No
WritePredictions = {Train}
ModelIDFiles = No
WriteCurves = No
OutputPythonModel = No
OutputDatabaseQueries = No

[Nominal]
MEstimate = 1.0

[Model]
MinimalWeight = 5.0
MinimalNumberExamples = 0
MinimalKnownWeight = 0.0
ParamTuneNumberFolds = 10
ClassWeights = 0.0
NominalSubsetTests = Yes

[Tree]
Heuristic = VarianceReduction
PruningMethod = ReducedErrorVSB
FTest = 1.0
BinarySplit = Yes
ConvertToRules = No
AlternativeSplits = No
Optimize = {}
MSENominal = No
SplitSampling = None
InductionOrder = DepthFirst

Run: 01
*******

Statistics
----------

FTValue (FTest): 1.0
Induction Time: 0.009 sec
Pruning Time: 0.002 sec
Model information
     Default: Nodes = 1 (Leaves: 1)
     Original: Nodes = 15 (Leaves: 8)
     Pruned: Nodes = 11 (Leaves: 6)

Training error
--------------

Number of examples: 159
Mean absolute error (MAE)
   Default        : [1.0909,1.0831,1.1336]: 1.1025
   Original       : [0.7521,0.7514,0.7725]: 0.7587
   Pruned         : [0.757,0.7516,0.793]: 0.7672
Mean squared error (MSE)
   Default        : [2.7879,2.6857,2.8736]: 2.7824
   Original       : [1.0574,1.1239,1.063]: 1.0815
   Pruned         : [1.0595,1.1242,1.0817]: 1.0885
Root mean squared error (RMSE)
   Default        : [1.6697,1.6388,1.6952]: 1.6681
   Original       : [1.0283,1.0602,1.031]: 1.0399
   Pruned         : [1.0293,1.0603,1.04]: 1.0433
Weighted root mean squared error (RMSE) (Weights [0.37,0.36,0.379])
   Default        : [1.0157,0.9833,1.0432]: 1.0144
   Original       : [0.6256,0.6361,0.6345]: 0.6321
   Pruned         : [0.6262,0.6362,0.64]: 0.6342
Pearson correlation coefficient
   Default        : [�,-0,�], Avg r^2: �
   Original       : [0.7879,0.7626,0.7938], Avg r^2: 0.6108
   Pruned         : [0.7874,0.7625,0.7897], Avg r^2: 0.6083

Validation error
----------------

Number of examples: 53
Mean absolute error (MAE)
   Default        : [0.9696,1.1163,0.8157]: 0.9672
   Original       : [0.8884,0.8627,0.7996]: 0.8502
   Pruned         : [0.8803,0.8609,0.7965]: 0.8459
Mean squared error (MSE)
   Default        : [2.4452,3.0529,1.9414]: 2.4799
   Original       : [1.2779,1.2898,0.9943]: 1.1873
   Pruned         : [1.2681,1.2894,0.9944]: 1.184
Root mean squared error (RMSE)
   Default        : [1.5637,1.7473,1.3934]: 1.5748
   Original       : [1.1304,1.1357,0.9971]: 1.0896
   Pruned         : [1.1261,1.1355,0.9972]: 1.0881
Weighted root mean squared error (RMSE) (Weights [0.37,0.36,0.379])
   Default        : [0.9513,1.0484,0.8575]: 0.9556
   Original       : [0.6877,0.6815,0.6136]: 0.6618
   Pruned         : [0.6851,0.6814,0.6137]: 0.6608
Pearson correlation coefficient
   Default        : [0,�,�], Avg r^2: �
   Original       : [0.7,0.7602,0.7266], Avg r^2: 0.532
   Pruned         : [0.7028,0.7603,0.7257], Avg r^2: 0.5328

Default Model
*************

[0.007822,0.024716,-0.033007]: 159

Original Model
**************

V4 > -2.367165
+--yes: V2 > -2.285053
|       +--yes: V3 > -2.120669
|       |       +--yes: [0.822843,0.7465,0.777145]: 89
|       |       +--no:  [-0.018973,-2.973438,-0.115201]: 22
|       +--no:  V2 > -3.308062
|               +--yes: [-2.720956,0.005658,0.307899]: 15
|               +--no:  [-3.589924,0.169843,-0.093077]: 8
+--no:  V3 > -0.053478
        +--yes: V4 > -3.122279
        |       +--yes: [-0.080409,0.3691,-2.785533]: 10
        |       +--no:  [-0.321888,0.412213,-3.484699]: 5
        +--no:  V4 > -2.885598
                +--yes: [0.155107,-0.376215,-2.681665]: 5
                +--no:  [-0.080047,-0.481513,-3.413262]: 5

Pruned Model
************

V4 > -2.367165
+--yes: V2 > -2.285053
|       +--yes: V3 > -2.120669
|       |       +--yes: [0.822843,0.7465,0.777145]: 89
|       |       +--no:  [-0.018973,-2.973438,-0.115201]: 22
|       +--no:  V2 > -3.308062
|               +--yes: [-2.720956,0.005658,0.307899]: 15
|               +--no:  [-3.589924,0.169843,-0.093077]: 8
+--no:  V3 > -0.053478
        +--yes: [-0.160902,0.383471,-3.018588]: 15
        +--no:  [0.03753,-0.428864,-3.047464]: 10

